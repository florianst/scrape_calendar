{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = None\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'trinity.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlbase = pickle.load(open('urlbase.pickle', 'rb'))\n",
    "\n",
    "hrefs = []\n",
    "for year in tqdm(range(2010, 2021)):\n",
    "    count_hrefs = 0\n",
    "    for month in range(1, 13):\n",
    "        # assemble URL of current month to extract hrefs of events\n",
    "        url = urlbase+\"/concerts?field_date_value%5Bvalue%5D%5Bmonth%5D=\"+str(month)\n",
    "        url += \"&field_date_value%5Bvalue%5D%5Byear%5D=\"+str(year)\n",
    "        url += \"&tid=All\"\n",
    "        \n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        for event in soup.find_all('div', class_=\"month mini-day-on\"):\n",
    "            hrefs.append(event.find_all('a')[0].get('href'))\n",
    "            count_hrefs += 1\n",
    "    \n",
    "    print(year, \"found\", count_hrefs)\n",
    "            \n",
    "print(hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(hrefs, open('hrefs.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs = pickle.load(open('hrefs.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "urlbase = pickle.load(open('urlbase.pickle', 'rb'))\n",
    "\n",
    "lines = []\n",
    "for href in tqdm(hrefs):\n",
    "    url = urlbase + href\n",
    "\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    suptitle = soup.find_all('h1', class_=\"title gutter\")[0].contents[0]\n",
    "\n",
    "    fields = soup.find_all('div', class_=\"field-items\")\n",
    "\n",
    "    try:\n",
    "        location, title, description = '', '', ''\n",
    "        datetime = soup.find_all('span', class_=\"date-display-single\")[0].get('content')[0:-9]\n",
    "        for i in range(len(fields)):\n",
    "            paragraphs = fields[i].find_all('p')\n",
    "            if len(paragraphs) > 0: \n",
    "                title = paragraphs[0].renderContents().decode(\"utf-8\")\n",
    "                if len(paragraphs) > 1:\n",
    "                    location = paragraphs[1].contents[0]\n",
    "                    if len(paragraphs) > 2: \n",
    "                        description = paragraphs[2].contents[0]\n",
    "                break\n",
    "                \n",
    "    except IndexError as e:\n",
    "        print(url)\n",
    "        print(soup.find_all('p')[0])\n",
    "        sys.exit()\n",
    "\n",
    "    artists, composers = [], []\n",
    "    composerMode = False # whether we're in the artist (False) or composer (True) column\n",
    "\n",
    "    subfields = [field.find_all('div', class_=\"field-item even\")[0] if len(field.find_all('div', class_=\"field-item even\")) > 0 else None for field in fields[2:]]\n",
    "    for subfield in subfields:\n",
    "        if subfield is not None: \n",
    "            subfield = subfield.next # enter subfield\n",
    "            if str(subfield).find('composer') > -1: composerMode = True\n",
    "            if str(subfield).find('<') == -1 and len(subfield) > 1: \n",
    "                if composerMode: composers.append(subfield)\n",
    "                else:            artists.append(subfield) # TODO: append things like Director/soprano/alto/tenor/bass to the previous element\n",
    "    \n",
    "    lines.append([datetime[0:10], datetime[11:16], suptitle, title, location, description, ','.join(artists), ','.join(composers), url])\n",
    "    \n",
    "print(len(lines), \"lines added successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lines, open('lines.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pickle.load(open('lines.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(filename, 'w+', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerow([\"date\", \"time\", \"suptitle\", \"title\", \"location\", \"description\", \"artists\", \"composers\", \"url\"])\n",
    "    for line in lines:\n",
    "        writer.writerow(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', None)\n",
    "csv = pd.read_csv(filename, keep_default_na=False)\n",
    "csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
