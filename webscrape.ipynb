{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "pd.options.display.max_rows = None\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "import sys\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'trinity.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get hrefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlbase = pickle.load(open('urlbase.pickle', 'rb'))\n",
    "\n",
    "hrefs = []\n",
    "for year in tqdm(range(2010, 2021)):\n",
    "    count_hrefs = 0\n",
    "    for month in range(1, 13):\n",
    "        # assemble URL of current month to extract hrefs of events\n",
    "        url = urlbase+\"/concerts?field_date_value%5Bvalue%5D%5Bmonth%5D=\"+str(month)\n",
    "        url += \"&field_date_value%5Bvalue%5D%5Byear%5D=\"+str(year)\n",
    "        url += \"&tid=All\"\n",
    "        \n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "        for event in soup.find_all('div', class_=\"month mini-day-on\"):\n",
    "            hrefs.append(event.find_all('a')[0].get('href'))\n",
    "            count_hrefs += 1\n",
    "    \n",
    "    print(year, \"found\", count_hrefs)\n",
    "            \n",
    "print(hrefs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(hrefs, open('hrefs.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hrefs = pickle.load(open('hrefs.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "urlbase = pickle.load(open('urlbase.pickle', 'rb'))\n",
    "\n",
    "lines = []\n",
    "for href in tqdm(hrefs):\n",
    "    url = urlbase + href\n",
    "\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    \n",
    "    suptitle = soup.find_all('h1', class_=\"title gutter\")[0].contents[0]\n",
    "\n",
    "    fields = soup.find_all('div', class_=\"field-items\")\n",
    "\n",
    "    try:\n",
    "        location, title, description = '', '', ''\n",
    "        datetime = soup.find_all('span', class_=\"date-display-single\")[0].get('content')[0:-9]\n",
    "        for i in range(len(fields)):\n",
    "            paragraphs = fields[i].find_all('p')\n",
    "            if len(paragraphs) > 0: \n",
    "                title = paragraphs[0].renderContents().decode(\"utf-8\")\n",
    "                if len(paragraphs) > 1:\n",
    "                    location = paragraphs[1].contents[0]\n",
    "                    if len(paragraphs) > 2: \n",
    "                        description = paragraphs[2].contents[0]\n",
    "                break\n",
    "                \n",
    "    except IndexError as e:\n",
    "        print(url)\n",
    "        print(soup.find_all('p')[0])\n",
    "        sys.exit()\n",
    "\n",
    "    artists, composers = [], []\n",
    "    composerMode = False # whether we're in the artist (False) or composer (True) column\n",
    "\n",
    "    subfields = [field.find_all('div', class_=\"field-item even\")[0] if len(field.find_all('div', class_=\"field-item even\")) > 0 else None for field in fields[2:]]\n",
    "    for subfield in subfields:\n",
    "        if subfield is not None: \n",
    "            subfield = subfield.next # enter subfield\n",
    "            if str(subfield).find('composer') > -1: composerMode = True\n",
    "            if str(subfield).find('<') == -1 and len(subfield) > 1: \n",
    "                if composerMode: composers.append(subfield)\n",
    "                else:            artists.append(subfield) # TODO: append things like Director/soprano/alto/tenor/bass to the previous element\n",
    "    \n",
    "    lines.append([datetime[0:10], datetime[11:16], suptitle, title, location, description, ', '.join(artists), ', '.join(composers), url])\n",
    "    \n",
    "print(len(lines), \"lines added successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(lines, open('lines.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = pickle.load(open('lines.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open(filename, 'w+', newline='', encoding='utf-8') as file:\n",
    "    writer = csv.writer(file, delimiter=',')\n",
    "    writer.writerow([\"date\", \"time\", \"suptitle\", \"title\", \"location\", \"description\", \"artists\", \"composers\", \"url\"])\n",
    "    for line in lines:\n",
    "        writer.writerow(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.set_option('display.max_colwidth', None)\n",
    "csv = pd.read_csv(filename, keep_default_na=False)\n",
    "csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dates(column=None, query=None, plot=False):\n",
    "    if column is not None and query is not None:\n",
    "        dates = [datetime.strptime(date, '%Y-%m-%d') for d, date in enumerate(csv[\"date\"]) if query in csv[column][d]]\n",
    "    else:\n",
    "        dates = [datetime.strptime(date, '%Y-%m-%d') for date in csv[\"date\"]]\n",
    "    df = pd.DataFrame({\"dates\": dates})\n",
    "    df.dates = pd.to_datetime(df.dates)\n",
    "    if plot:\n",
    "        df.groupby(df.dates.dt.year).count().plot(kind='bar')   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tcc = count_dates(\"artists\", \"Trinity College\", True)\n",
    "polyphony = count_dates(\"artists\", \"Polyphony\", True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = count_dates()\n",
    "count = df['dates'].groupby([df.dates.dt.year, df.dates.dt.month]).agg('count')\n",
    "count_years = [date[0] for date in count.index.values]\n",
    "count_months = [date[1] for date in count.index.values]\n",
    "df = pd.DataFrame({\"Year\": count_years, \"Month\": count_months, \"Count\":count.values})\n",
    "pt = df.pivot_table(index=\"Month\", columns=\"Year\", values=\"Count\", aggfunc=\"sum\").fillna(0)\n",
    "months = [\"Jan\", \"Feb\", \"Mar\", \"Apr\", \"May\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "sns.heatmap(pt, annot=True, cmap=\"Purples\", yticklabels=months)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
